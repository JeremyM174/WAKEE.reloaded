{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc02cac",
   "metadata": {},
   "source": [
    "# Explo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59a7fa93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, random, shutil, glob, boto3, requests, json\n",
    "from datetime import datetime, date\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c835368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frame177039021230.jpg', 'frame177039021347.jpg', 'frame177039021408.jpg', 'frame177039021461.jpg', 'frame177039021520.jpg', 'frame177039021572.jpg', 'frame177039021625.jpg', 'frame177039021679.jpg', 'frame177039021733.jpg', 'frame177039021786.jpg', 'frame177039021839.jpg', 'frame177039021898.jpg', 'frame177039021948.jpg', 'frame177039022006.jpg', 'frame177039022067.jpg', 'frame177039022117.jpg', 'frame177039022169.jpg', 'frame177039022225.jpg', 'frame177039022281.jpg', 'frame177039022342.jpg', 'frame177039022392.jpg', 'frame177039022438.jpg', 'frame177039022498.jpg', 'frame177039022548.jpg', 'frame177039022607.jpg', 'frame177039022654.jpg', 'frame177039022711.jpg', 'frame177039022758.jpg', 'frame177039022818.jpg', 'frame177039022868.jpg', 'frame177039022927.jpg', 'frame177039022980.jpg', 'frame177039023039.jpg', 'frame177039023092.jpg', 'frame177039023148.jpg', 'frame177039023205.jpg', 'frame177039023268.jpg', 'frame177039023323.jpg', 'frame177039023389.jpg', 'frame177039023450.jpg', 'frame177039023508.jpg', 'frame177039023565.jpg', 'frame177039023628.jpg', 'frame177039023696.jpg', 'frame177039023762.jpg', 'frame177039023826.jpg', 'frame177039023877.jpg', 'frame177039023937.jpg', 'frame177039024002.jpg', 'frame177039024066.jpg', 'frame177039024114.jpg', 'frame177039024174.jpg', 'frame177039024233.jpg', 'frame177039024297.jpg', 'frame177039024348.jpg', 'frame177039024400.jpg', 'frame177039024450.jpg', 'frame177039024498.jpg', 'frame177039024546.jpg', 'frame177039024598.jpg', 'frame177039024652.jpg', 'frame177039024716.jpg', 'frame177039024775.jpg', 'frame177039024836.jpg', 'frame177039024896.jpg', 'frame177039024942.jpg', 'frame177039024992.jpg', 'frame177039025052.jpg', 'frame177039025102.jpg', 'frame177039025155.jpg', 'frame177039025201.jpg', 'frame177039025258.jpg', 'frame177039025311.jpg', 'frame177039025361.jpg', 'frame177039025417.jpg', 'frame177039025475.jpg', 'frame177039025534.jpg', 'frame177039025586.jpg', 'frame177039025633.jpg', 'frame177039025700.jpg', 'frame177039025747.jpg', 'frame177039025788.jpg', 'frame177039025837.jpg', 'frame177039025893.jpg', 'frame177039025948.jpg', 'frame177039026004.jpg', 'frame177039026061.jpg', 'frame177039026119.jpg', 'frame177039026173.jpg', 'frame177039026236.jpg', 'frame177039026296.jpg', 'frame177039026342.jpg', 'frame177039026403.jpg', 'frame177039026462.jpg', 'frame177039026519.jpg', 'frame177039026579.jpg', 'frame177039026629.jpg', 'frame177039026691.jpg', 'frame177039026745.jpg', 'frame177039026804.jpg', 'frame177039027000.jpg', 'frame177039027060.jpg', 'frame177039027120.jpg', 'frame177039027174.jpg', 'frame177039027230.jpg', 'frame177039027287.jpg', 'frame177039027348.jpg', 'frame177050640719.jpg', 'frame177050640861.jpg', 'frame177050640906.jpg', 'frame177050640965.jpg', 'frame177050641013.jpg', 'frame177050641083.jpg', 'frame177050641134.jpg']\n"
     ]
    }
   ],
   "source": [
    "valid_extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".gif\")\n",
    "frame_files = []\n",
    "for captured_frames in os.listdir(\"temp\"):\n",
    "    if captured_frames.lower().endswith(valid_extensions):\n",
    "        frame_files.append(captured_frames)\n",
    "print(frame_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96659155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>boredom</th>\n",
       "      <th>engagement</th>\n",
       "      <th>confusion</th>\n",
       "      <th>frustration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frame177039022392.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_path  boredom  engagement  confusion  frustration\n",
       "0  frame177039022392.jpg        3           1          0            1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"temp/frame177039022392.jpg.csv\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a1860e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frame177039022392.jpg.csv', 'frame177039023092.jpg.csv', 'frame177039023877.jpg.csv', 'frame177051044261.jpg.csv', 'frame177062785670.jpg.csv']\n",
      "['frame177039022392.jpg', 'frame177039023092.jpg', 'frame177039023877.jpg', 'frame177051044261.jpg', 'frame177062785670.jpg']\n"
     ]
    }
   ],
   "source": [
    "csv_list = []\n",
    "frame_list = []\n",
    "\n",
    "for csv_file in os.listdir(\"temp\"):\n",
    "    if csv_file.lower().endswith(\".csv\"):\n",
    "        csv_list.append(csv_file)\n",
    "        shutil.move(f\"temp/{csv_file}\", f\"backup/{csv_file}\")\n",
    "\n",
    "for frame in csv_list:\n",
    "    frame = frame.replace(\".csv\", \"\")\n",
    "    frame_list.append(frame)\n",
    "    shutil.move(f\"temp/{frame}\", f\"backup/{frame}\")\n",
    "\n",
    "print(csv_list)\n",
    "print(frame_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb7e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>boredom</th>\n",
       "      <th>engagement</th>\n",
       "      <th>confusion</th>\n",
       "      <th>frustration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frame177039022392.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frame177039023092.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frame177039023877.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frame177051044261.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frame177062785670.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_path  boredom  engagement  confusion  frustration\n",
       "0  frame177039022392.jpg        3           1          0            1\n",
       "1  frame177039023092.jpg        2           0          0            0\n",
       "2  frame177039023877.jpg        3           1          0            2\n",
       "3  frame177051044261.jpg        3           1          0            2\n",
       "4  frame177062785670.jpg        0           2          3            1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = glob.glob(os.path.join(\"temp\", \"*.csv\"))\n",
    "\n",
    "df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3098b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"daily_ratings{date.today()}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde9fdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frame177039022392.jpg.csv', 'frame177039023092.jpg.csv', 'frame177039023877.jpg.csv', 'frame177051044261.jpg.csv', 'frame177062785670.jpg.csv']\n",
      "['frame177039022392.jpg', 'frame177039023092.jpg', 'frame177039023877.jpg', 'frame177051044261.jpg', 'frame177062785670.jpg']\n"
     ]
    }
   ],
   "source": [
    "csv_list = []\n",
    "frame_list = []\n",
    "\n",
    "for csv_file in os.listdir(\"temp\"):\n",
    "    if csv_file.lower().endswith(\".csv\"):\n",
    "        csv_list.append(csv_file)\n",
    "\n",
    "for frame in csv_list:\n",
    "    frame = frame.replace(\".csv\", \"\")\n",
    "    frame_list.append(frame)\n",
    "\n",
    "print(csv_list)\n",
    "print(frame_list)\n",
    "\n",
    "rated_files = glob.glob(os.path.join(\"temp\", \"*.csv\"))\n",
    "df_rated = pd.concat((pd.read_csv(f) for f in rated_files), ignore_index=True)\n",
    "df_rated.to_csv(f\"temp/daily_ratings{date.today()}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c56dd305",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id = aws_access_key_id,\n",
    "    aws_secret_access_key = aws_secret_access_key\n",
    ")\n",
    "s3 = session.resource(\"s3\")\n",
    "bucket = s3.Bucket(\"deploymentproject174\")\n",
    "#bucket.upload_file(f\"temp/daily_ratings{date.today()}.csv\", f\"wakee_reloaded/daily_ratings{date.today()}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f022a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_file in frame_list:\n",
    "    bucket.upload_file(f\"temp/{frame_file}\", f\"wakee_reloaded/{frame_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9411d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadDirectoryFroms3(bucketName, remoteDirectoryName):\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    bucket = s3_resource.Bucket(bucketName) \n",
    "    for obj in bucket.objects.filter(Prefix = remoteDirectoryName):\n",
    "        if not os.path.exists(os.path.dirname(obj.key)):\n",
    "            os.makedirs(os.path.dirname(obj.key))\n",
    "        bucket.download_file(obj.key, obj.key) # save to same path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc46873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def download_s3_prefix(bucket_name, s3_prefix, local_dir):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "\n",
    "    for page in paginator.paginate(Bucket=bucket_name, Prefix=s3_prefix):\n",
    "        if \"Contents\" not in page:\n",
    "            continue\n",
    "\n",
    "        for obj in page[\"Contents\"]:\n",
    "            s3_key = obj[\"Key\"]\n",
    "\n",
    "            # Skip \"directory markers\" (zero-byte objects ending with /)\n",
    "            if s3_key.endswith(\"/\"):\n",
    "                continue\n",
    "\n",
    "            # Compute local file path\n",
    "            relative_path = os.path.relpath(s3_key, s3_prefix)\n",
    "            local_path = os.path.join(local_dir, relative_path)\n",
    "\n",
    "            # Ensure local directory exists\n",
    "            os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "\n",
    "            try:\n",
    "                s3.download_file(bucket_name, s3_key, local_path)\n",
    "                print(f\"Downloaded: {s3_key} ‚Üí {local_path}\")\n",
    "            except ClientError as e:\n",
    "                print(f\"Failed to download {s3_key}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fd73c794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: wakee_reloaded/daily_ratings2026-02-09.csv ‚Üí temp\\daily_ratings2026-02-09.csv\n",
      "Downloaded: wakee_reloaded/frame177039022392.jpg ‚Üí temp\\frame177039022392.jpg\n",
      "Downloaded: wakee_reloaded/frame177039023092.jpg ‚Üí temp\\frame177039023092.jpg\n",
      "Downloaded: wakee_reloaded/frame177039023877.jpg ‚Üí temp\\frame177039023877.jpg\n",
      "Downloaded: wakee_reloaded/frame177051044261.jpg ‚Üí temp\\frame177051044261.jpg\n",
      "Downloaded: wakee_reloaded/frame177062785670.jpg ‚Üí temp\\frame177062785670.jpg\n",
      "Downloaded: wakee_reloaded/temptest/WAKEE_image.png ‚Üí temp\\temptest\\WAKEE_image.png\n"
     ]
    }
   ],
   "source": [
    "download_s3_prefix(\"deploymentproject174\", \"wakee_reloaded\", \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e0ce5ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daily_ratings2026-02-09.csv']\n"
     ]
    }
   ],
   "source": [
    "path = 'temp/'\n",
    "files = []\n",
    "for i in os.listdir(path):\n",
    "    if os.path.isfile(os.path.join(path,i)) and 'daily_ratings' in i:\n",
    "        files.append(i)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f8426c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>boredom</th>\n",
       "      <th>engagement</th>\n",
       "      <th>confusion</th>\n",
       "      <th>frustration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frame177039022392.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frame177039023092.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frame177039023877.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frame177051044261.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frame177062785670.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>frame177071468159.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>frame177071470618.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Train\\110001\\1100011002\\1100011002.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Train\\110001\\1100011003\\1100011003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Train\\110001\\1100011004\\1100011004.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               image_path  boredom  engagement  confusion  \\\n",
       "0                   frame177039022392.jpg        3           1          0   \n",
       "1                   frame177039023092.jpg        2           0          0   \n",
       "2                   frame177039023877.jpg        3           1          0   \n",
       "3                   frame177051044261.jpg        3           1          0   \n",
       "4                   frame177062785670.jpg        0           2          3   \n",
       "5                   frame177071468159.jpg        2           0          1   \n",
       "6                   frame177071470618.jpg        1           2          0   \n",
       "7  Train\\110001\\1100011002\\1100011002.jpg        0           2          0   \n",
       "8  Train\\110001\\1100011003\\1100011003.jpg        0           2          0   \n",
       "9  Train\\110001\\1100011004\\1100011004.jpg        0           3          0   \n",
       "\n",
       "   frustration  \n",
       "0            1  \n",
       "1            0  \n",
       "2            2  \n",
       "3            2  \n",
       "4            1  \n",
       "5            0  \n",
       "6            1  \n",
       "7            0  \n",
       "8            0  \n",
       "9            0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfiles = glob.glob(os.path.join(\"training/archive\", \"*.csv\"))\n",
    "df_ctest = pd.concat((pd.read_csv(f) for f in rfiles), ignore_index=True)\n",
    "df_ctest.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e730c9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a90f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, classification_report \n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06b31dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, emotion_cols, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.emotion_cols = emotion_cols\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['image_path'])\n",
    "\n",
    "        emotion_labels = row[self.emotion_cols].values.astype(float)\n",
    "        emotion_labels = torch.tensor(emotion_labels, dtype=torch.float32)\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, emotion_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81fa85c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"training/archive\"\n",
    "CSV_FILE = os.path.join(DATA_DIR, 'labels_daisee_continous.csv')\n",
    "IMAGE_DIR = os.path.join(DATA_DIR, 'DataSet')\n",
    "\n",
    "# Define your emotions here, in the same order as your columns in the CSV\n",
    "EMOTION_LABELS = ['boredom', 'confusion', 'engagement', 'frustration']\n",
    "NUM_CLASSES = len(EMOTION_LABELS)\n",
    "\n",
    "BATCH_SIZE = 32 \n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "FREEZE_FEATURES = True # True to fine-tune only the last layer, False to fine-tune the entire model\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "EXPERIMENT_NAME=\"WAKEE.reloaded\"\n",
    "mlflow.set_tracking_uri(os.environ[\"TRACKING_SERVER_URI\"])\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "mlflow.pytorch.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "905535f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\.conda\\envs\\wakee_rldd\\lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "624fb5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size : 6354\n",
      "Testing dataset size : 1589\n"
     ]
    }
   ],
   "source": [
    "full_df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "train_df, val_df = train_test_split(full_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = EmotionDataset(df=train_df, img_dir=IMAGE_DIR, emotion_cols=EMOTION_LABELS, transform=data_transforms['val'])\n",
    "val_dataset = EmotionDataset(df=val_df, img_dir=IMAGE_DIR, emotion_cols=EMOTION_LABELS, transform=data_transforms['val'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
    "\n",
    "print(f\"Training dataset size : {dataset_sizes['train']}\")\n",
    "print(f\"Testing dataset size : {dataset_sizes['val']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0c7bbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.7.1.block.0.1.weight\n",
      "features.7.1.block.0.1.bias\n",
      "features.7.1.block.1.0.weight\n",
      "features.7.1.block.1.1.weight\n",
      "features.7.1.block.1.1.bias\n",
      "features.7.1.block.2.fc1.weight\n",
      "features.7.1.block.2.fc1.bias\n",
      "features.7.1.block.2.fc2.weight\n",
      "features.7.1.block.2.fc2.bias\n",
      "features.7.1.block.3.0.weight\n",
      "features.7.1.block.3.1.weight\n",
      "features.7.1.block.3.1.bias\n",
      "features.8.0.weight\n",
      "features.8.1.weight\n",
      "features.8.1.bias\n",
      "classifier.1.weight\n",
      "classifier.1.bias\n",
      "D√©finition de la derni√®re couche...\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.efficientnet_b4(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "# layers freeze\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# fine_tune_at = len(list(model_ft.children())) - 10\n",
    "for name, param in list(model_ft.named_parameters())[-17:]:\n",
    "    print(name)\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(\"D√©finition de la derni√®re couche...\")\n",
    "\n",
    "# 3. Replacing the final fully-connected layer\n",
    "num_ftrs = model_ft.classifier[1].in_features\n",
    "\n",
    "model_ft.classifier = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(512, NUM_CLASSES)\n",
    ")\n",
    "\n",
    "# 4. Sending the model to the correct device (GPU or CPU)\n",
    "model_ft = model_ft.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78da9efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "EfficientNet                                            [1, 4]                    --\n",
       "‚îú‚îÄSequential: 1-1                                       [1, 1792, 7, 7]           --\n",
       "‚îÇ    ‚îî‚îÄConv2dNormActivation: 2-1                        [1, 48, 112, 112]         --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-1                                 [1, 48, 112, 112]         (1,296)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-2                            [1, 48, 112, 112]         (96)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄSiLU: 3-3                                   [1, 48, 112, 112]         --\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-2                                  [1, 24, 112, 112]         --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-4                                 [1, 24, 112, 112]         (2,940)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-5                                 [1, 24, 112, 112]         (1,206)\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-3                                  [1, 32, 56, 56]           --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-6                                 [1, 32, 56, 56]           (11,878)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-7                                 [1, 32, 56, 56]           (18,120)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-8                                 [1, 32, 56, 56]           (18,120)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-9                                 [1, 32, 56, 56]           (18,120)\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-4                                  [1, 56, 28, 28]           --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-10                                [1, 56, 28, 28]           (25,848)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-11                                [1, 56, 28, 28]           (57,246)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-12                                [1, 56, 28, 28]           (57,246)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-13                                [1, 56, 28, 28]           (57,246)\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-5                                  [1, 112, 14, 14]          --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-14                                [1, 112, 14, 14]          (70,798)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-15                                [1, 112, 14, 14]          (197,820)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-16                                [1, 112, 14, 14]          (197,820)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-17                                [1, 112, 14, 14]          (197,820)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-18                                [1, 112, 14, 14]          (197,820)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-19                                [1, 112, 14, 14]          (197,820)\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-6                                  [1, 160, 14, 14]          --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-20                                [1, 160, 14, 14]          (240,924)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-21                                [1, 160, 14, 14]          (413,160)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-22                                [1, 160, 14, 14]          (413,160)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-23                                [1, 160, 14, 14]          (413,160)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-24                                [1, 160, 14, 14]          (413,160)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-25                                [1, 160, 14, 14]          (413,160)\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-7                                  [1, 272, 7, 7]            --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-26                                [1, 272, 7, 7]            (520,904)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-27                                [1, 272, 7, 7]            (1,159,332)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-28                                [1, 272, 7, 7]            (1,159,332)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-29                                [1, 272, 7, 7]            (1,159,332)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-30                                [1, 272, 7, 7]            (1,159,332)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-31                                [1, 272, 7, 7]            (1,159,332)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-32                                [1, 272, 7, 7]            (1,159,332)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-33                                [1, 272, 7, 7]            (1,159,332)\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-8                                  [1, 448, 7, 7]            --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-34                                [1, 448, 7, 7]            (1,420,804)\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄMBConv: 3-35                                [1, 448, 7, 7]            3,049,200\n",
       "‚îÇ    ‚îî‚îÄConv2dNormActivation: 2-9                        [1, 1792, 7, 7]           --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-36                                [1, 1792, 7, 7]           802,816\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-37                           [1, 1792, 7, 7]           3,584\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄSiLU: 3-38                                  [1, 1792, 7, 7]           --\n",
       "‚îú‚îÄAdaptiveAvgPool2d: 1-2                                [1, 1792, 1, 1]           --\n",
       "‚îú‚îÄSequential: 1-3                                       [1, 4]                    --\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-10                                     [1, 512]                  918,016\n",
       "‚îÇ    ‚îî‚îÄBatchNorm1d: 2-11                                [1, 512]                  1,024\n",
       "‚îÇ    ‚îî‚îÄReLU: 2-12                                       [1, 512]                  --\n",
       "‚îÇ    ‚îî‚îÄDropout: 2-13                                    [1, 512]                  --\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-14                                     [1, 4]                    2,052\n",
       "=========================================================================================================\n",
       "Total params: 18,469,708\n",
       "Trainable params: 3,572,468\n",
       "Non-trainable params: 14,897,240\n",
       "Total mult-adds (G): 1.50\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 272.50\n",
       "Params size (MB): 73.88\n",
       "Estimated Total Size (MB): 346.98\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_ft, input_size=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2331147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=random.randint(2,5)\n",
    "criterion_emotions = nn.MSELoss()\n",
    "\n",
    "# Only parameters that require gradients will be optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Learning rate scheduler (reduces LR after a certain number of epochs)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e109251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, \n",
    "                criterion_emotions, \n",
    "                optimizer, \n",
    "                train_loader, \n",
    "                val_loader, \n",
    "                device, \n",
    "                scheduler=None,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                output_names=EMOTION_LABELS):\n",
    "    \n",
    "    since = time.time()\n",
    "    \n",
    "    history = {'train_loss': [],\n",
    "                'val_loss': [],\n",
    "                'val_MAE': [],\n",
    "                'val_MSE': [],\n",
    "                'val_RMSE': [],\n",
    "                'val_R2': []}\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        print('-' * 30)\n",
    "\n",
    "        ### -------- TRAIN --------\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion_emotions(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "\n",
    "        ### -------- VAL --------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_predictions = []\n",
    "        val_true_values = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion_emotions(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Convert tensors to numpy to calculate sklearn metrics\n",
    "                val_predictions.extend(outputs.cpu().numpy())\n",
    "                val_true_values.extend(labels.cpu().numpy())\n",
    "\n",
    "                preds = torch.round(outputs)\n",
    "                preds = torch.clip(preds, 0, 3)\n",
    "\n",
    "                all_preds.append(preds.cpu())\n",
    "                all_labels.append(labels.cpu())\n",
    "\n",
    "        # Concatenation of all batches\n",
    "        all_preds = torch.cat(all_preds).numpy()\n",
    "        all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "        # Convert lists to numpy array for sklearn\n",
    "        val_true_values_np = np.array(val_true_values)\n",
    "        val_predictions_np = np.array(val_predictions)\n",
    "\n",
    "        val_epoch_loss = val_loss / len(val_loader.dataset)\n",
    "        val_epoch_MAE = mean_absolute_error(val_true_values_np, val_predictions_np)\n",
    "        val_epoch_MSE = mean_squared_error(val_true_values_np, val_predictions_np)\n",
    "        val_epoch_RMSE = np.sqrt(mean_squared_error(val_true_values_np, val_predictions_np))\n",
    "        val_epoch_r2 = r2_score(val_true_values_np, val_predictions_np)\n",
    "        \n",
    "        history['val_loss'].append(val_epoch_loss)\n",
    "        history['val_MAE'].append(val_epoch_MAE)\n",
    "        history['val_MSE'].append(val_epoch_MSE)\n",
    "        history['val_RMSE'].append(val_epoch_RMSE)\n",
    "        history['val_R2'].append(val_epoch_r2)\n",
    "       \n",
    "        print(f\"Train Loss: {epoch_loss:.4f} | \"\n",
    "            f\"Val Loss: {val_epoch_loss:.4f} | \"\n",
    "            f\"Val MAE: {val_epoch_MAE:.4f} | \"\n",
    "            f\"Val MSE: {val_epoch_MSE:.4f} | \"\n",
    "            f\"Val RMSE: {val_epoch_RMSE:.4f} | \"\n",
    "            f\"Val R2: {val_epoch_r2:.4f} \\n \")\n",
    "        \n",
    "        # Displaying the multi-label classification report\n",
    "        # print(\"\\nüìä Rapport de classification multilabels-multiouputs :\")\n",
    "        \n",
    "        # target_names_classes = ['0', '1', '2', '3'] # Class names for the report\n",
    "\n",
    "        # for i, names in enumerate(output_names):\n",
    "        #     print(f\"\\n--- Variable {names} ---\")\n",
    "            \n",
    "        #     # The real classes for the variable i\n",
    "        #     y_true_var_i = all_labels[:, i]\n",
    "            \n",
    "        #     # The classified predictions for variable i\n",
    "        #     y_pred_var_i = all_preds[:, i]\n",
    "            \n",
    "        #     # Check that the values are integers and within the expected range\n",
    "        #     if not np.all(np.isin(y_true_var_i, [0, 1, 2, 3])):\n",
    "        #         print(f\"Attention: y_true pour la variable {names} contient des valeurs hors de [0, 3] ou non enti√®res apr√®s arrondi.\")\n",
    "        #     if not np.all(np.isin(y_pred_var_i, [0, 1, 2, 3])):\n",
    "        #         print(f\"Attention: y_pred pour la variable {names} contient des valeurs hors de [0, 3] ou non enti√®res apr√®s arrondi.\")\n",
    "\n",
    "            # Generate and display the report.\n",
    "            # print(classification_report(y_true_var_i, y_pred_var_i, target_names=target_names_classes, zero_division=0))\n",
    "        \n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"\\nüïí Entra√Ænement termin√© en {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5047d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best performances (id, MAE): ('e43ae9be3e844c52a8cd8952e1a75e3b', 0.5337298512458801)\n",
      "\n",
      "Epoch 1/2\n",
      "------------------------------\n",
      "Train Loss: 0.3963 | Val Loss: 0.4506 | Val MAE: 0.5121 | Val MSE: 0.4506 | Val RMSE: 0.6713 | Val R2: 0.1001 \n",
      " \n",
      "\n",
      "Epoch 2/2\n",
      "------------------------------\n",
      "Train Loss: 0.3928 | Val Loss: 0.4534 | Val MAE: 0.5229 | Val MSE: 0.4534 | Val RMSE: 0.6734 | Val R2: 0.0935 \n",
      " \n",
      "\n",
      "üïí Entra√Ænement termin√© en 2m 15s\n",
      "\n",
      "New best MAE: 0.522926926612854 against former 0.5337298512458801\n",
      "\n",
      "Pushing new model to MLflow to replace e43ae9be3e844c52a8cd8952e1a75e3b!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/13 19:51:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'reloaded_model'.\n",
      "2026/02/13 19:51:42 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: reloaded_model, version 1\n",
      "Created version '1' of model 'reloaded_model'.\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_30504\\4283215961.py:81: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run trusting-mink-294 at: https://mevelios-mlflowtest.hf.space/#/experiments/4/runs/b165cceff4f5411abc48a097b419abbd\n",
      "üß™ View experiment at: https://mevelios-mlflowtest.hf.space/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "# comparison start\n",
    "MLFLOW_URL = os.getenv(\"TRACKING_SERVER_URI\")\n",
    "EXPERIMENT_ID = \"4\"\n",
    "\n",
    "search_endpoint = f\"{MLFLOW_URL}/api/2.0/mlflow/runs/search\"\n",
    "\n",
    "search_data = {\n",
    "    \"experiment_ids\": [EXPERIMENT_ID],\n",
    "    \"filter_string\": \"tags.mlflow.log-model.history IS NOT NULL\",\n",
    "    \"max_results\": 1000\n",
    "}\n",
    "\n",
    "search_resp = requests.post(search_endpoint, json=search_data)\n",
    "search_resp.raise_for_status()\n",
    "\n",
    "runs = search_resp.json().get(\"runs\", [])\n",
    "\n",
    "# collect metrics for each run\n",
    "model_runs = []\n",
    "\n",
    "for run in runs:\n",
    "    run_id = run[\"info\"][\"run_id\"]\n",
    "    metrics = run.get(\"data\", {}).get(\"metrics\", {})\n",
    "    \n",
    "    model_runs.append({\n",
    "        \"run_id\": run_id,\n",
    "        \"metrics\": metrics\n",
    "    })\n",
    "\n",
    "# compare best metric against current run\n",
    "best_mae = {}\n",
    "for item in model_runs:\n",
    "    best_mae[f'{item[\"run_id\"]}'] = item[\"metrics\"][0][\"value\"]\n",
    "\n",
    "sorted_by_values = sorted(best_mae.items(), key=lambda item: item[1])\n",
    "best_logged_run = next(iter(sorted_by_values))\n",
    "print(f\"Current best performances (id, MAE): {best_logged_run}\")\n",
    "\n",
    "former_model_exp = best_logged_run[0]\n",
    "best_logged_mae = best_logged_run[1]\n",
    "\n",
    "# training start\n",
    "with mlflow.start_run(experiment_id = experiment.experiment_id):\n",
    "    history = train_model(model=model_ft,\n",
    "                            criterion_emotions=criterion_emotions,\n",
    "                            optimizer=optimizer_ft,\n",
    "                            train_loader=train_loader,\n",
    "                            val_loader=val_loader,\n",
    "                            device=DEVICE,\n",
    "                            scheduler=exp_lr_scheduler,\n",
    "                            epochs=2, #epochs, # replace with 2 for quick training\n",
    "                            output_names=EMOTION_LABELS)\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        \"MAE\":history[\"val_MAE\"][-1],\n",
    "        \"MSE\":history[\"val_MSE\"][-1],\n",
    "        \"RMSE\":history[\"val_RMSE\"][-1],\n",
    "        \"R¬≤\":history[\"val_R2\"][-1],\n",
    "        \"Val train\":history[\"train_loss\"][-1],\n",
    "        \"Val loss\":history[\"val_loss\"][-1]\n",
    "    })\n",
    "    \n",
    "    mlflow.log_params({\n",
    "        \"Epochs\":epochs,\n",
    "        \"Loss function\":criterion_emotions,\n",
    "        \"Optimizer\":optimizer_ft,\n",
    "        \"LR/step size\":exp_lr_scheduler.step_size,\n",
    "        \"LR/gamma\":exp_lr_scheduler.gamma\n",
    "    })\n",
    "    current_mae = history[\"val_MAE\"][-1]\n",
    "\n",
    "    if current_mae < best_logged_mae:\n",
    "        print(f\"\\nNew best MAE: {current_mae} against former {best_logged_mae}\")\n",
    "        print(f\"\\nPushing new model to MLflow to replace {former_model_exp}!\")\n",
    "        #here new process - remove model_info variable storing, keep log_model, remove what's next until else statement\n",
    "        model_info = mlflow.pytorch.log_model(model_ft, name=f\"model{date.today()}\")\n",
    "        model_uri = model_info.model_uri\n",
    "        registered_model = mlflow.register_model(model_uri=model_uri, name=\"reloaded_model\")\n",
    "\n",
    "        client = MlflowClient()\n",
    "        client.transition_model_version_stage(\n",
    "            name=\"reloaded_model\",\n",
    "            version=registered_model.version,\n",
    "            stage=\"Production\"\n",
    "            )\n",
    "    \n",
    "    else:\n",
    "        print(f\"\\nPerformance target missed: current MAE {current_mae} higher than reference {best_logged_mae}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0142ed00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_30504\\2793752283.py:15: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  prod_versions = client.get_latest_versions(name=MODEL_NAME, stages=[\"Production\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Production MAE: 0.522926926612854\n",
      "\n",
      "Epoch 1/2\n",
      "------------------------------\n",
      "Train Loss: 0.3934 | Val Loss: 0.4546 | Val MAE: 0.5136 | Val MSE: 0.4546 | Val RMSE: 0.6742 | Val R2: 0.0937 \n",
      " \n",
      "\n",
      "Epoch 2/2\n",
      "------------------------------\n",
      "Train Loss: 0.3848 | Val Loss: 0.4522 | Val MAE: 0.5195 | Val MSE: 0.4522 | Val RMSE: 0.6725 | Val R2: 0.0963 \n",
      " \n",
      "\n",
      "üïí Entra√Ænement termin√© en 5m 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/13 22:46:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New training MAE: 0.5194727182388306\n",
      "New model is better. Promoting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/13 22:46:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'reloaded_model' already exists. Creating a new version of this model...\n",
      "2026/02/13 22:46:42 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: reloaded_model, version 2\n",
      "Created version '2' of model 'reloaded_model'.\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_30504\\2793752283.py:75: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:01<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved locally at: c:\\Users\\maria\\Desktop\\dsl_ft_33\\00_Projets_certif\\bloc4\\03_Jedha_aia_bloc_4_Final_project\\wakee_lead\\src\\best_model\\\n",
      "üèÉ View run handsome-pug-246 at: https://mevelios-mlflowtest.hf.space/#/experiments/4/runs/82104f45db1a4948afb5d71d4ca7104a\n",
      "üß™ View experiment at: https://mevelios-mlflowtest.hf.space/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# CONFIG\n",
    "# =========================================\n",
    "TRACKING_URI = os.getenv(\"TRACKING_SERVER_URI\")\n",
    "MODEL_NAME = \"reloaded_model\"\n",
    "METRIC_NAME = \"MAE\"\n",
    "LOCAL_BEST_DIR = \"./best_model\"\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "\n",
    "# =========================================\n",
    "# STEP 1 ‚Äî Get MAE of Production model\n",
    "# =========================================\n",
    "prod_versions = client.get_latest_versions(name=MODEL_NAME, stages=[\"Production\"])\n",
    "\n",
    "# if not prod_versions:\n",
    "#     raise Exception(\"No model in Production stage.\")\n",
    "\n",
    "prod_model_version = prod_versions[0]\n",
    "prod_run_id = prod_model_version.run_id\n",
    "\n",
    "prod_run = client.get_run(prod_run_id)\n",
    "prod_mae = prod_run.data.metrics[METRIC_NAME]\n",
    "\n",
    "print(f\"Current Production MAE: {prod_mae}\")\n",
    "\n",
    "# =========================================\n",
    "# STEP 2 ‚Äî Train new model (metrics only)\n",
    "# =========================================\n",
    "\n",
    "with mlflow.start_run(experiment_id = experiment.experiment_id):\n",
    "    history = train_model(model=model_ft,\n",
    "                            criterion_emotions=criterion_emotions,\n",
    "                            optimizer=optimizer_ft,\n",
    "                            train_loader=train_loader,\n",
    "                            val_loader=val_loader,\n",
    "                            device=DEVICE,\n",
    "                            scheduler=exp_lr_scheduler,\n",
    "                            epochs=2, #epochs, # replace with 2 for quick training\n",
    "                            output_names=EMOTION_LABELS)\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        \"MAE\":history[\"val_MAE\"][-1],\n",
    "        \"MSE\":history[\"val_MSE\"][-1],\n",
    "        \"RMSE\":history[\"val_RMSE\"][-1],\n",
    "        \"R¬≤\":history[\"val_R2\"][-1],\n",
    "        \"Val train\":history[\"train_loss\"][-1],\n",
    "        \"Val loss\":history[\"val_loss\"][-1]\n",
    "    })\n",
    "    \n",
    "    mlflow.log_params({\n",
    "        \"Epochs\":epochs,\n",
    "        \"Loss function\":criterion_emotions,\n",
    "        \"Optimizer\":optimizer_ft,\n",
    "        \"LR/step size\":exp_lr_scheduler.step_size,\n",
    "        \"LR/gamma\":exp_lr_scheduler.gamma\n",
    "    })\n",
    "    current_mae = history[\"val_MAE\"][-1]\n",
    "    print(f\"New training MAE: {current_mae}\")\n",
    "\n",
    "    # =========================================\n",
    "    # STEP 3 ‚Äî Compare\n",
    "    # =========================================\n",
    "    if current_mae < prod_mae:\n",
    "        print(\"New model is better. Promoting...\")\n",
    "\n",
    "        # Log model artifact\n",
    "        model_info = mlflow.pytorch.log_model(model_ft, name=\"model\")\n",
    "\n",
    "        # Register model\n",
    "        registered_model = mlflow.register_model(model_uri=model_info.model_uri, name=MODEL_NAME)\n",
    "\n",
    "        # Promote to Production\n",
    "        client.transition_model_version_stage(\n",
    "            name=MODEL_NAME,\n",
    "            version=registered_model.version,\n",
    "            stage=\"Production\"\n",
    "        )\n",
    "\n",
    "        # =========================================\n",
    "        # STEP 4 ‚Äî Save locally\n",
    "        # =========================================\n",
    "        local_path = mlflow.artifacts.download_artifacts(\n",
    "            artifact_uri=model_info.model_uri,\n",
    "            dst_path=LOCAL_BEST_DIR\n",
    "        )\n",
    "\n",
    "        print(f\"New best model saved locally at: {local_path}\")\n",
    "\n",
    "    else:\n",
    "        print(\"New model did not beat Production. Nothing promoted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4669d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model : training/daisee_model.onnx\n"
     ]
    }
   ],
   "source": [
    "onnx_export_path = \"training/daisee_model.onnx\"\n",
    "\n",
    "# Dummy input ‚Äî must match the size expected by your model\n",
    "dummy_input = torch.randn(1, 3, 224, 224, device=DEVICE)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model_ft,                  \n",
    "    dummy_input,               \n",
    "    onnx_export_path,          \n",
    "    input_names=['input'],     \n",
    "    output_names=['output'],   \n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    },\n",
    "    opset_version=11,          # ONNX opset version (11 is safe for compatibility)\n",
    "    do_constant_folding=True   # Optimization for constants\n",
    ")\n",
    "\n",
    "print(f\"Exported model : {onnx_export_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687112a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a1d963e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest run ID: f1075fc7cf584a528e7033eb2d8a2fe0\n"
     ]
    }
   ],
   "source": [
    "MLFLOW_URL = \"https://mevelios-mlflowtest.hf.space\"  # your tracking server\n",
    "\n",
    "# Step 1: Search for latest run\n",
    "search_endpoint = f\"{MLFLOW_URL}/api/2.0/mlflow/runs/search\"\n",
    "search_data = {\n",
    "    \"experiment_ids\": [\"4\"],\n",
    "    \"max_results\": 1,\n",
    "    \"order_by\": [\"attributes.start_time DESC\"]\n",
    "}\n",
    "\n",
    "search_resp = requests.post(search_endpoint, json=search_data)\n",
    "search_resp.raise_for_status()\n",
    "\n",
    "runs = search_resp.json().get(\"runs\", [])\n",
    "if not runs:\n",
    "    print(\"No runs found\")\n",
    "    exit()\n",
    "\n",
    "latest_run = runs[0]\n",
    "run_id = latest_run[\"info\"][\"run_id\"]\n",
    "print(f\"Latest run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba703cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metrics\": [\n",
      "    {\n",
      "      \"key\": \"MAE\",\n",
      "      \"value\": 0.5344879031181335,\n",
      "      \"timestamp\": 1770818393743,\n",
      "      \"step\": 0\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"MSE\",\n",
      "      \"value\": 0.4726739823818207,\n",
      "      \"timestamp\": 1770818393743,\n",
      "      \"step\": 0\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"RMSE\",\n",
      "      \"value\": 0.6875128746032715,\n",
      "      \"timestamp\": 1770818393743,\n",
      "      \"step\": 0\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"R\\u00b2\",\n",
      "      \"value\": 0.06388531625270844,\n",
      "      \"timestamp\": 1770818393743,\n",
      "      \"step\": 0\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"Val train\",\n",
      "      \"value\": 0.5029744265775433,\n",
      "      \"timestamp\": 1770818393743,\n",
      "      \"step\": 0\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"Val loss\",\n",
      "      \"value\": 0.472673933373974,\n",
      "      \"timestamp\": 1770818393743,\n",
      "      \"step\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"params\": [\n",
      "    {\n",
      "      \"key\": \"Epochs\",\n",
      "      \"value\": \"3\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"Loss function\",\n",
      "      \"value\": \"MSELoss()\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"Optimizer\",\n",
      "      \"value\": \"Adam (\\nParameter Group 0\\n    amsgrad: False\\n    betas: (0.9, 0.999)\\n    capturable: False\\n    decoupled_weight_decay: False\\n    differentiable: False\\n    eps: 1e-08\\n    foreach: None\\n    fused: None\\n    initial_lr: 0.001\\n    lr: 0.001\\n    maximize: False\\n    weight_decay: 0\\n)\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"LR/step size\",\n",
      "      \"value\": \"7\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"LR/gamma\",\n",
      "      \"value\": \"0.1\"\n",
      "    }\n",
      "  ],\n",
      "  \"tags\": [\n",
      "    {\n",
      "      \"key\": \"mlflow.user\",\n",
      "      \"value\": \"airflow\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"mlflow.source.name\",\n",
      "      \"value\": \"/home/airflow/.local/bin/airflow\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"mlflow.source.type\",\n",
      "      \"value\": \"LOCAL\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"mlflow.runName\",\n",
      "      \"value\": \"bald-yak-998\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Get run details\n",
    "get_endpoint = f\"{MLFLOW_URL}/api/2.0/mlflow/runs/get\"\n",
    "params = {\"run_id\": run_id}\n",
    "\n",
    "get_resp = requests.get(get_endpoint, params=params)\n",
    "get_resp.raise_for_status()\n",
    "\n",
    "run_data = get_resp.json().get(\"run\", {}).get(\"data\", {})\n",
    "print(json.dumps(run_data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a8cd63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key': 'MAE',\n",
       " 'value': 0.5344879031181335,\n",
       " 'timestamp': 1770818393743,\n",
       " 'step': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_data.get(\"metrics\", {})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b336c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 runs with logged models.\n",
      "\n",
      "Run ID: e43ae9be3e844c52a8cd8952e1a75e3b\n",
      "[\n",
      "  {\n",
      "    \"key\": \"MAE\",\n",
      "    \"value\": 0.5337298512458801,\n",
      "    \"timestamp\": 1770892334889,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"MSE\",\n",
      "    \"value\": 0.4947755038738251,\n",
      "    \"timestamp\": 1770892334889,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"RMSE\",\n",
      "    \"value\": 0.7034028172492981,\n",
      "    \"timestamp\": 1770892334889,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"R\\u00b2\",\n",
      "    \"value\": 0.0657166838645935,\n",
      "    \"timestamp\": 1770892334889,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"Val train\",\n",
      "    \"value\": 0.4503036236853197,\n",
      "    \"timestamp\": 1770892334889,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"Val loss\",\n",
      "    \"value\": 0.4947757315064439,\n",
      "    \"timestamp\": 1770892334889,\n",
      "    \"step\": 0\n",
      "  }\n",
      "]\n",
      "----------------------------------------\n",
      "Run ID: 02d8b00a9a714d1bbd96984daca818dd\n",
      "[\n",
      "  {\n",
      "    \"key\": \"MAE\",\n",
      "    \"value\": 0.5643874406814575,\n",
      "    \"timestamp\": 1770891873589,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"MSE\",\n",
      "    \"value\": 0.4946451187133789,\n",
      "    \"timestamp\": 1770891873589,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"RMSE\",\n",
      "    \"value\": 0.7033101320266724,\n",
      "    \"timestamp\": 1770891873589,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"R\\u00b2\",\n",
      "    \"value\": 0.06028951704502106,\n",
      "    \"timestamp\": 1770891873589,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"Val train\",\n",
      "    \"value\": 0.45504553035408973,\n",
      "    \"timestamp\": 1770891873589,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"Val loss\",\n",
      "    \"value\": 0.4946451105205589,\n",
      "    \"timestamp\": 1770891873589,\n",
      "    \"step\": 0\n",
      "  }\n",
      "]\n",
      "----------------------------------------\n",
      "Run ID: f1075fc7cf584a528e7033eb2d8a2fe0\n",
      "[\n",
      "  {\n",
      "    \"key\": \"MAE\",\n",
      "    \"value\": 0.5344879031181335,\n",
      "    \"timestamp\": 1770818393743,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"MSE\",\n",
      "    \"value\": 0.4726739823818207,\n",
      "    \"timestamp\": 1770818393743,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"RMSE\",\n",
      "    \"value\": 0.6875128746032715,\n",
      "    \"timestamp\": 1770818393743,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"R\\u00b2\",\n",
      "    \"value\": 0.06388531625270844,\n",
      "    \"timestamp\": 1770818393743,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"Val train\",\n",
      "    \"value\": 0.5029744265775433,\n",
      "    \"timestamp\": 1770818393743,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"Val loss\",\n",
      "    \"value\": 0.472673933373974,\n",
      "    \"timestamp\": 1770818393743,\n",
      "    \"step\": 0\n",
      "  }\n",
      "]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Filter runs that contain this metric\u001b[39;00m\n\u001b[0;32m     52\u001b[0m filtered \u001b[38;5;241m=\u001b[39m [r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m model_runs \u001b[38;5;28;01mif\u001b[39;00m METRIC_NAME \u001b[38;5;129;01min\u001b[39;00m r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m---> 54\u001b[0m best_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetrics\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mMETRIC_NAME\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAXIMIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müèÜ Best run based on metric:\u001b[39m\u001b[38;5;124m\"\u001b[39m, METRIC_NAME)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_run[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "MLFLOW_URL = \"https://mevelios-mlflowtest.hf.space\"\n",
    "EXPERIMENT_ID = \"4\"\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Search runs with logged models\n",
    "# -----------------------------\n",
    "\n",
    "search_endpoint = f\"{MLFLOW_URL}/api/2.0/mlflow/runs/search\"\n",
    "\n",
    "search_data = {\n",
    "    \"experiment_ids\": [EXPERIMENT_ID],\n",
    "    \"filter_string\": \"tags.mlflow.log-model.history IS NOT NULL\",\n",
    "    \"max_results\": 1000\n",
    "}\n",
    "\n",
    "search_resp = requests.post(search_endpoint, json=search_data)\n",
    "search_resp.raise_for_status()\n",
    "\n",
    "runs = search_resp.json().get(\"runs\", [])\n",
    "\n",
    "print(f\"Found {len(runs)} runs with logged models.\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Collect metrics for each run\n",
    "# -----------------------------\n",
    "\n",
    "model_runs = []\n",
    "\n",
    "for run in runs:\n",
    "    run_id = run[\"info\"][\"run_id\"]\n",
    "    metrics = run.get(\"data\", {}).get(\"metrics\", {})\n",
    "    \n",
    "    model_runs.append({\n",
    "        \"run_id\": run_id,\n",
    "        \"metrics\": metrics\n",
    "    })\n",
    "\n",
    "# Print available runs and metrics\n",
    "for r in model_runs:\n",
    "    print(f\"Run ID: {r['run_id']}\")\n",
    "    print(json.dumps(r[\"metrics\"], indent=2))\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Select best model by chosen metric\n",
    "# -----------------------------\n",
    "\n",
    "METRIC_NAME = \"MAE\"      # üîÅ change to your metric\n",
    "MAXIMIZE = False               # True for accuracy, False for loss\n",
    "\n",
    "# Filter runs that contain this metric\n",
    "filtered = [r for r in model_runs if METRIC_NAME in r[\"metrics\"]]\n",
    "\n",
    "best_run = sorted(filtered, key=lambda x: x[\"metrics\"][METRIC_NAME], reverse=MAXIMIZE)[0]\n",
    "\n",
    "print(\"\\nüèÜ Best run based on metric:\", METRIC_NAME)\n",
    "print(\"Run ID:\", best_run[\"run_id\"])\n",
    "print(\"Metric value:\", best_run[\"metrics\"][METRIC_NAME])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66e7a526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key': 'MAE',\n",
       " 'value': 0.5344879031181335,\n",
       " 'timestamp': 1770818393743,\n",
       " 'step': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['metrics'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c36cfa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0ec1544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 runs with logged models.\n",
      "\n",
      "Run ID: e43ae9be3e844c52a8cd8952e1a75e3b\n",
      "[\n",
      "  {\n",
      "    \"key\": \"MAE\",\n",
      "    \"value\": 0.5337298512458801,\n",
      "    \"timestamp\": 1770892334889,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"MSE\",\n",
      "    \"value\": 0.4947755038738251,\n",
      "    \"timestamp\": 1770892334889,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"RMSE\",\n",
      "    \"value\": 0.7034028172492981,\n",
      "    \"timestamp\": 1770892334889,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"R\\u00b2\",\n",
      "    \"value\": 0.0657166838645935,\n",
      "    \"timestamp\": 1770892334889,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"Val train\",\n",
      "    \"value\": 0.4503036236853197,\n",
      "    \"timestamp\": 1770892334889,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"Val loss\",\n",
      "    \"value\": 0.4947757315064439,\n",
      "    \"timestamp\": 1770892334889,\n",
      "    \"step\": 0\n",
      "  }\n",
      "]\n",
      "----------------------------------------\n",
      "Run ID: 02d8b00a9a714d1bbd96984daca818dd\n",
      "[\n",
      "  {\n",
      "    \"key\": \"MAE\",\n",
      "    \"value\": 0.5643874406814575,\n",
      "    \"timestamp\": 1770891873589,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"MSE\",\n",
      "    \"value\": 0.4946451187133789,\n",
      "    \"timestamp\": 1770891873589,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"RMSE\",\n",
      "    \"value\": 0.7033101320266724,\n",
      "    \"timestamp\": 1770891873589,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"R\\u00b2\",\n",
      "    \"value\": 0.06028951704502106,\n",
      "    \"timestamp\": 1770891873589,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"Val train\",\n",
      "    \"value\": 0.45504553035408973,\n",
      "    \"timestamp\": 1770891873589,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"Val loss\",\n",
      "    \"value\": 0.4946451105205589,\n",
      "    \"timestamp\": 1770891873589,\n",
      "    \"step\": 0\n",
      "  }\n",
      "]\n",
      "----------------------------------------\n",
      "Run ID: f1075fc7cf584a528e7033eb2d8a2fe0\n",
      "[\n",
      "  {\n",
      "    \"key\": \"MAE\",\n",
      "    \"value\": 0.5344879031181335,\n",
      "    \"timestamp\": 1770818393743,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"MSE\",\n",
      "    \"value\": 0.4726739823818207,\n",
      "    \"timestamp\": 1770818393743,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"RMSE\",\n",
      "    \"value\": 0.6875128746032715,\n",
      "    \"timestamp\": 1770818393743,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"R\\u00b2\",\n",
      "    \"value\": 0.06388531625270844,\n",
      "    \"timestamp\": 1770818393743,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"Val train\",\n",
      "    \"value\": 0.5029744265775433,\n",
      "    \"timestamp\": 1770818393743,\n",
      "    \"step\": 0\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"Val loss\",\n",
      "    \"value\": 0.472673933373974,\n",
      "    \"timestamp\": 1770818393743,\n",
      "    \"step\": 0\n",
      "  }\n",
      "]\n",
      "----------------------------------------\n",
      "\n",
      "üèÜ Best run based on metric: MAE\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m best_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(filtered, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m], reverse\u001b[38;5;241m=\u001b[39mMAXIMIZE)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müèÜ Best run based on metric:\u001b[39m\u001b[38;5;124m\"\u001b[39m, METRIC_NAME)\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mbest_run\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetric value:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_run[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "MLFLOW_URL = \"https://mevelios-mlflowtest.hf.space\"\n",
    "EXPERIMENT_ID = \"4\"\n",
    "\n",
    "search_endpoint = f\"{MLFLOW_URL}/api/2.0/mlflow/runs/search\"\n",
    "\n",
    "search_data = {\n",
    "    \"experiment_ids\": [EXPERIMENT_ID],\n",
    "    \"filter_string\": \"tags.mlflow.log-model.history IS NOT NULL\",\n",
    "    \"max_results\": 1000\n",
    "}\n",
    "\n",
    "search_resp = requests.post(search_endpoint, json=search_data)\n",
    "search_resp.raise_for_status()\n",
    "\n",
    "runs = search_resp.json().get(\"runs\", [])\n",
    "\n",
    "print(f\"Found {len(runs)} runs with logged models.\\n\")\n",
    "\n",
    "# Step 2: Collect metrics for each run\n",
    "model_runs = []\n",
    "\n",
    "for run in runs:\n",
    "    run_id = run[\"info\"][\"run_id\"]\n",
    "    metrics = run.get(\"data\", {}).get(\"metrics\", {})\n",
    "    \n",
    "    model_runs.append({\n",
    "        \"run_id\": run_id,\n",
    "        \"metrics\": metrics\n",
    "    })\n",
    "\n",
    "# Print available runs and metrics\n",
    "for r in model_runs:\n",
    "    print(f\"Run ID: {r['run_id']}\")\n",
    "    print(json.dumps(r[\"metrics\"], indent=2))\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Step 3: Select best model by chosen metric\n",
    "\n",
    "METRIC_NAME = \"MAE\"      # üîÅ change to your metric\n",
    "MAXIMIZE = False               # True for accuracy, False for loss\n",
    "\n",
    "# Filter runs that contain this metric\n",
    "filtered = [r for r in model_runs if METRIC_NAME in r[\"metrics\"][0]['key']]\n",
    "\n",
    "best_run = sorted(filtered, key=lambda x: x[\"metrics\"][0][\"value\"], reverse=MAXIMIZE)\n",
    "\n",
    "print(\"\\nüèÜ Best run based on metric:\", METRIC_NAME)\n",
    "print(\"Run ID:\", best_run[\"run_id\"])\n",
    "print(\"Metric value:\", best_run[\"metrics\"][0][\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22993593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'run_id': 'e43ae9be3e844c52a8cd8952e1a75e3b',\n",
       "  'metrics': [{'key': 'MAE',\n",
       "    'value': 0.5337298512458801,\n",
       "    'timestamp': 1770892334889,\n",
       "    'step': 0},\n",
       "   {'key': 'MSE',\n",
       "    'value': 0.4947755038738251,\n",
       "    'timestamp': 1770892334889,\n",
       "    'step': 0},\n",
       "   {'key': 'RMSE',\n",
       "    'value': 0.7034028172492981,\n",
       "    'timestamp': 1770892334889,\n",
       "    'step': 0},\n",
       "   {'key': 'R¬≤',\n",
       "    'value': 0.0657166838645935,\n",
       "    'timestamp': 1770892334889,\n",
       "    'step': 0},\n",
       "   {'key': 'Val train',\n",
       "    'value': 0.4503036236853197,\n",
       "    'timestamp': 1770892334889,\n",
       "    'step': 0},\n",
       "   {'key': 'Val loss',\n",
       "    'value': 0.4947757315064439,\n",
       "    'timestamp': 1770892334889,\n",
       "    'step': 0}]},\n",
       " {'run_id': '02d8b00a9a714d1bbd96984daca818dd',\n",
       "  'metrics': [{'key': 'MAE',\n",
       "    'value': 0.5643874406814575,\n",
       "    'timestamp': 1770891873589,\n",
       "    'step': 0},\n",
       "   {'key': 'MSE',\n",
       "    'value': 0.4946451187133789,\n",
       "    'timestamp': 1770891873589,\n",
       "    'step': 0},\n",
       "   {'key': 'RMSE',\n",
       "    'value': 0.7033101320266724,\n",
       "    'timestamp': 1770891873589,\n",
       "    'step': 0},\n",
       "   {'key': 'R¬≤',\n",
       "    'value': 0.06028951704502106,\n",
       "    'timestamp': 1770891873589,\n",
       "    'step': 0},\n",
       "   {'key': 'Val train',\n",
       "    'value': 0.45504553035408973,\n",
       "    'timestamp': 1770891873589,\n",
       "    'step': 0},\n",
       "   {'key': 'Val loss',\n",
       "    'value': 0.4946451105205589,\n",
       "    'timestamp': 1770891873589,\n",
       "    'step': 0}]},\n",
       " {'run_id': 'f1075fc7cf584a528e7033eb2d8a2fe0',\n",
       "  'metrics': [{'key': 'MAE',\n",
       "    'value': 0.5344879031181335,\n",
       "    'timestamp': 1770818393743,\n",
       "    'step': 0},\n",
       "   {'key': 'MSE',\n",
       "    'value': 0.4726739823818207,\n",
       "    'timestamp': 1770818393743,\n",
       "    'step': 0},\n",
       "   {'key': 'RMSE',\n",
       "    'value': 0.6875128746032715,\n",
       "    'timestamp': 1770818393743,\n",
       "    'step': 0},\n",
       "   {'key': 'R¬≤',\n",
       "    'value': 0.06388531625270844,\n",
       "    'timestamp': 1770818393743,\n",
       "    'step': 0},\n",
       "   {'key': 'Val train',\n",
       "    'value': 0.5029744265775433,\n",
       "    'timestamp': 1770818393743,\n",
       "    'step': 0},\n",
       "   {'key': 'Val loss',\n",
       "    'value': 0.472673933373974,\n",
       "    'timestamp': 1770818393743,\n",
       "    'step': 0}]}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e05ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5337298512458801, 0.5643874406814575, 0.5344879031181335]\n",
      "0.5337298512458801\n"
     ]
    }
   ],
   "source": [
    "MAE_values = []\n",
    "runs_list = []\n",
    "for item in model_runs:\n",
    "    MAE_values.append((item[\"metrics\"][0][\"value\"]))\n",
    "    runs_list.append(item[\"run_id\"])\n",
    "print(MAE_values)\n",
    "print(min(MAE_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aafc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test = {\"run_id\":[], \"MAE\":[]}\n",
    "for item in model_runs:\n",
    "    dict_test.append((item[\"metrics\"][0][\"value\"]))\n",
    "    runs_list.append(item[\"run_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e922498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e43ae9be3e844c52a8cd8952e1a75e3b': 0.5337298512458801,\n",
       " '02d8b00a9a714d1bbd96984daca818dd': 0.5643874406814575,\n",
       " 'f1075fc7cf584a528e7033eb2d8a2fe0': 0.5344879031181335}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mae = {}\n",
    "for item in model_runs:\n",
    "    best_mae[f'{item[\"run_id\"]}'] = item[\"metrics\"][0][\"value\"]\n",
    "best_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fb42d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e43ae9be3e844c52a8cd8952e1a75e3b', 0.5337298512458801),\n",
       " ('f1075fc7cf584a528e7033eb2d8a2fe0', 0.5344879031181335),\n",
       " ('02d8b00a9a714d1bbd96984daca818dd', 0.5643874406814575)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_by_values = sorted(best_mae.items(), key=lambda item: item[1])\n",
    "sorted_by_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c36040b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('e43ae9be3e844c52a8cd8952e1a75e3b', 0.5337298512458801)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(sorted_by_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4ac90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 runs with logged models.\n",
      "\n",
      "('e43ae9be3e844c52a8cd8952e1a75e3b', 0.5337298512458801) e43ae9be3e844c52a8cd8952e1a75e3b 0.5337298512458801\n"
     ]
    }
   ],
   "source": [
    "MLFLOW_URL = \"https://mevelios-mlflowtest.hf.space\"\n",
    "EXPERIMENT_ID = \"4\"\n",
    "\n",
    "search_endpoint = f\"{MLFLOW_URL}/api/2.0/mlflow/runs/search\"\n",
    "\n",
    "search_data = {\n",
    "    \"experiment_ids\": [EXPERIMENT_ID],\n",
    "    \"filter_string\": \"tags.mlflow.log-model.history IS NOT NULL\",\n",
    "    \"max_results\": 1000\n",
    "}\n",
    "\n",
    "search_resp = requests.post(search_endpoint, json=search_data)\n",
    "search_resp.raise_for_status()\n",
    "\n",
    "runs = search_resp.json().get(\"runs\", [])\n",
    "\n",
    "# collect metrics for each run\n",
    "model_runs = []\n",
    "\n",
    "for run in runs:\n",
    "    run_id = run[\"info\"][\"run_id\"]\n",
    "    metrics = run.get(\"data\", {}).get(\"metrics\", {})\n",
    "    \n",
    "    model_runs.append({\n",
    "        \"run_id\": run_id,\n",
    "        \"metrics\": metrics\n",
    "    })\n",
    "\n",
    "# compare best metric against current run\n",
    "best_mae = {}\n",
    "for item in model_runs:\n",
    "    best_mae[f'{item[\"run_id\"]}'] = item[\"metrics\"][0][\"value\"]\n",
    "\n",
    "sorted_by_values = sorted(best_mae.items(), key=lambda item: item[1])\n",
    "best_logged_run = next(iter(sorted_by_values))\n",
    "print(f\"Current best performances (id,MAE): {best_logged_run}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61088b9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No valid logged PyTorch model found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_run \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo valid logged PyTorch model found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected run: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_run\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_run\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mmetrics[METRIC_NAME]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: No valid logged PyTorch model found."
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Configuration\n",
    "# ==============================\n",
    "TRACKING_URI = \"https://mevelios-mlflowtest.hf.space\"\n",
    "EXPERIMENT_ID = \"4\"\n",
    "METRIC_NAME = \"MAE\"\n",
    "LOCAL_DOWNLOAD_DIR = \"./best_model\"\n",
    "\n",
    "# ==============================\n",
    "# Connect\n",
    "# ==============================\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "\n",
    "# ==============================\n",
    "# Step 1 ‚Äî Get runs sorted by MAE (ascending)\n",
    "# ==============================\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[EXPERIMENT_ID],\n",
    "    filter_string=\"metrics.MAE > 0\",\n",
    "    order_by=[\"metrics.MAE ASC\"]\n",
    ")\n",
    "\n",
    "if not runs:\n",
    "    raise Exception(\"No runs found.\")\n",
    "\n",
    "# ==============================\n",
    "# Step 2 ‚Äî Find best run that has a loadable model\n",
    "# ==============================\n",
    "best_run = None\n",
    "model_uri = None\n",
    "\n",
    "for run in runs:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    artifacts = client.list_artifacts(run_id)\n",
    "\n",
    "    for artifact in artifacts:\n",
    "        if artifact.is_dir:\n",
    "            candidate_uri = f\"runs:/{run_id}/{artifact.path}\"\n",
    "            try:\n",
    "                # Try loading as PyTorch model\n",
    "                mlflow.pytorch.load_model(candidate_uri)\n",
    "                best_run = run\n",
    "                model_uri = candidate_uri\n",
    "                break\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    if best_run:\n",
    "        break\n",
    "\n",
    "if best_run is None:\n",
    "    raise Exception(\"No valid logged PyTorch model found.\")\n",
    "\n",
    "print(f\"Selected run: {best_run.info.run_id}\")\n",
    "print(f\"Best MAE: {best_run.data.metrics[METRIC_NAME]}\")\n",
    "print(f\"Model URI: {model_uri}\")\n",
    "\n",
    "# ==============================\n",
    "# Step 3 ‚Äî Download model locally\n",
    "# ==============================\n",
    "local_path = mlflow.artifacts.download_artifacts(\n",
    "    artifact_uri=model_uri,\n",
    "    dst_path=LOCAL_DOWNLOAD_DIR\n",
    ")\n",
    "\n",
    "print(f\"\\nModel downloaded to: {local_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "435b8813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4ac44f735b6c4ae3a7c1db4a63178e55\n",
      "[]\n",
      "53be9bda702f4f8c9a45b091a518808c\n",
      "[]\n",
      "e9a7e7855d2e4f4c8ee8095412fc25de\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for run in runs[:3]:\n",
    "    print(run.info.run_id)\n",
    "    print(client.list_artifacts(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "640256af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4ac44f735b6c4ae3a7c1db4a63178e55\n",
      "s3://mlflowtest-dsfsft35/4/4ac44f735b6c4ae3a7c1db4a63178e55/artifacts\n",
      "53be9bda702f4f8c9a45b091a518808c\n",
      "s3://mlflowtest-dsfsft35/4/53be9bda702f4f8c9a45b091a518808c/artifacts\n",
      "e9a7e7855d2e4f4c8ee8095412fc25de\n",
      "s3://mlflowtest-dsfsft35/4/e9a7e7855d2e4f4c8ee8095412fc25de/artifacts\n"
     ]
    }
   ],
   "source": [
    "for run in runs[:3]:\n",
    "    print(run.info.run_id)\n",
    "    print(run.info.artifact_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2af6f719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:01<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run: c086f11a86ac4976aff137034069eff4\n",
      "Best MAE: 0.5161923766136169\n",
      "Model URI: runs:/c086f11a86ac4976aff137034069eff4/model2026-02-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:01<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded to: c:\\Users\\maria\\Desktop\\dsl_ft_33\\00_Projets_certif\\bloc4\\03_Jedha_aia_bloc_4_Final_project\\wakee_lead\\src\\best_model\\model2026-02-13\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Config\n",
    "# ==============================\n",
    "TRACKING_URI = os.getenv(\"TRACKING_SERVER_URI\")\n",
    "EXPERIMENT_ID = \"4\"\n",
    "METRIC_NAME = \"MAE\"\n",
    "LOCAL_DOWNLOAD_DIR = \"./best_model\"\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "\n",
    "# ==============================\n",
    "# Step 1 ‚Äî Sort runs by MAE\n",
    "# ==============================\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[EXPERIMENT_ID],\n",
    "    filter_string=\"metrics.MAE > 0\",\n",
    "    order_by=[\"metrics.MAE ASC\"]\n",
    ")\n",
    "\n",
    "if not runs:\n",
    "    raise Exception(\"No runs found.\")\n",
    "\n",
    "# ==============================\n",
    "# Step 2 ‚Äî Attempt loading based on known naming pattern\n",
    "# ==============================\n",
    "best_run = None\n",
    "model_uri = None\n",
    "\n",
    "for run in runs:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    # You logged model as: modelYYYY-MM-DD\n",
    "    # Extract run start time to reconstruct date\n",
    "    run_date = run.info.start_time  # milliseconds timestamp\n",
    "    run_date = date.fromtimestamp(run_date / 1000)\n",
    "\n",
    "    candidate_path = f\"model{run_date}\"\n",
    "    candidate_uri = f\"runs:/{run_id}/{candidate_path}\"\n",
    "\n",
    "    try:\n",
    "        mlflow.pytorch.load_model(candidate_uri)\n",
    "        best_run = run\n",
    "        model_uri = candidate_uri\n",
    "        break\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "if best_run is None:\n",
    "    raise Exception(\"No loadable model found.\")\n",
    "\n",
    "print(f\"Best run: {best_run.info.run_id}\")\n",
    "print(f\"Best MAE: {best_run.data.metrics[METRIC_NAME]}\")\n",
    "print(f\"Model URI: {model_uri}\")\n",
    "\n",
    "# ==============================\n",
    "# Step 3 ‚Äî Download\n",
    "# ==============================\n",
    "local_path = mlflow.artifacts.download_artifacts(\n",
    "    artifact_uri=model_uri,\n",
    "    dst_path=LOCAL_DOWNLOAD_DIR\n",
    ")\n",
    "\n",
    "print(f\"Model downloaded to: {local_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7a4da70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.search_registered_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4deed201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "repo = Repo(\"WAKEE_reloaded_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d8f528c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100644, 05571f0a1fae09c26081344850ac48901c9d9a7d, 0, model/daisee_model.onnx)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.index.add([\"model/daisee_model.onnx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c71a3af4",
   "metadata": {},
   "outputs": [
    {
     "ename": "HookExecutionError",
     "evalue": "Hook('c:\\Users\\maria\\Desktop\\dsl_ft_33\\00_Projets_certif\\bloc4\\03_Jedha_aia_bloc_4_Final_project\\wakee_lead\\src\\WAKEE_reloaded_API\\.git\\hooks\\post-commit') failed due to: exit code(2)\n  cmdline: c:\\Users\\maria\\Desktop\\dsl_ft_33\\00_Projets_certif\\bloc4\\03_Jedha_aia_bloc_4_Final_project\\wakee_lead\\src\\WAKEE_reloaded_API\\.git\\hooks\\post-commit\n  stderr: '\nThis repository is configured for Git LFS but 'git-lfs' was not found on your path. If you no longer wish to use Git LFS, remove this hook by deleting the 'post-commit' file in the hooks directory (set by 'core.hookspath'; usually '.git/hooks').\n\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHookExecutionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAPI model update\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maria\\.conda\\envs\\wakee_rldd\\lib\\site-packages\\git\\index\\base.py:1174\u001b[0m, in \u001b[0;36mIndexFile.commit\u001b[1;34m(self, message, parent_commits, head, author, committer, author_date, commit_date, skip_hooks)\u001b[0m\n\u001b[0;32m   1162\u001b[0m rval \u001b[38;5;241m=\u001b[39m Commit\u001b[38;5;241m.\u001b[39mcreate_from_tree(\n\u001b[0;32m   1163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo,\n\u001b[0;32m   1164\u001b[0m     tree,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     commit_date\u001b[38;5;241m=\u001b[39mcommit_date,\n\u001b[0;32m   1172\u001b[0m )\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_hooks:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[43mrun_commit_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost-commit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rval\n",
      "File \u001b[1;32mc:\\Users\\maria\\.conda\\envs\\wakee_rldd\\lib\\site-packages\\git\\index\\fun.py:118\u001b[0m, in \u001b[0;36mrun_commit_hook\u001b[1;34m(name, index, *args)\u001b[0m\n\u001b[0;32m    116\u001b[0m stdout \u001b[38;5;241m=\u001b[39m force_text(stdout, defenc)\n\u001b[0;32m    117\u001b[0m stderr \u001b[38;5;241m=\u001b[39m force_text(stderr, defenc)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HookExecutionError(hp, process\u001b[38;5;241m.\u001b[39mreturncode, stderr, stdout)\n",
      "\u001b[1;31mHookExecutionError\u001b[0m: Hook('c:\\Users\\maria\\Desktop\\dsl_ft_33\\00_Projets_certif\\bloc4\\03_Jedha_aia_bloc_4_Final_project\\wakee_lead\\src\\WAKEE_reloaded_API\\.git\\hooks\\post-commit') failed due to: exit code(2)\n  cmdline: c:\\Users\\maria\\Desktop\\dsl_ft_33\\00_Projets_certif\\bloc4\\03_Jedha_aia_bloc_4_Final_project\\wakee_lead\\src\\WAKEE_reloaded_API\\.git\\hooks\\post-commit\n  stderr: '\nThis repository is configured for Git LFS but 'git-lfs' was not found on your path. If you no longer wish to use Git LFS, remove this hook by deleting the 'post-commit' file in the hooks directory (set by 'core.hookspath'; usually '.git/hooks').\n\n'"
     ]
    }
   ],
   "source": [
    "repo.index.commit(\"API model update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0043596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".gitattributes\n",
      "model/daisee_model.onnx\n"
     ]
    }
   ],
   "source": [
    "diffs = repo.index.diff(None)\n",
    "for d in diffs:\n",
    "    print(d.a_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1df284b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model/daisee_model.onnx']\n"
     ]
    }
   ],
   "source": [
    "add_file = [d.a_path]  # relative path from git root\n",
    "print(add_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ef672e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100644, 05571f0a1fae09c26081344850ac48901c9d9a7d, 0, model/daisee_model.onnx)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.index.add(add_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35f78be5",
   "metadata": {},
   "outputs": [
    {
     "ename": "HookExecutionError",
     "evalue": "Hook('c:\\Users\\maria\\Desktop\\dsl_ft_33\\00_Projets_certif\\bloc4\\03_Jedha_aia_bloc_4_Final_project\\wakee_lead\\src\\WAKEE_reloaded_API\\.git\\hooks\\post-commit') failed due to: exit code(2)\n  cmdline: c:\\Users\\maria\\Desktop\\dsl_ft_33\\00_Projets_certif\\bloc4\\03_Jedha_aia_bloc_4_Final_project\\wakee_lead\\src\\WAKEE_reloaded_API\\.git\\hooks\\post-commit\n  stderr: '\nThis repository is configured for Git LFS but 'git-lfs' was not found on your path. If you no longer wish to use Git LFS, remove this hook by deleting the 'post-commit' file in the hooks directory (set by 'core.hookspath'; usually '.git/hooks').\n\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHookExecutionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAPI model update\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maria\\.conda\\envs\\wakee_rldd\\lib\\site-packages\\git\\index\\base.py:1174\u001b[0m, in \u001b[0;36mIndexFile.commit\u001b[1;34m(self, message, parent_commits, head, author, committer, author_date, commit_date, skip_hooks)\u001b[0m\n\u001b[0;32m   1162\u001b[0m rval \u001b[38;5;241m=\u001b[39m Commit\u001b[38;5;241m.\u001b[39mcreate_from_tree(\n\u001b[0;32m   1163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo,\n\u001b[0;32m   1164\u001b[0m     tree,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     commit_date\u001b[38;5;241m=\u001b[39mcommit_date,\n\u001b[0;32m   1172\u001b[0m )\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_hooks:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[43mrun_commit_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost-commit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rval\n",
      "File \u001b[1;32mc:\\Users\\maria\\.conda\\envs\\wakee_rldd\\lib\\site-packages\\git\\index\\fun.py:118\u001b[0m, in \u001b[0;36mrun_commit_hook\u001b[1;34m(name, index, *args)\u001b[0m\n\u001b[0;32m    116\u001b[0m stdout \u001b[38;5;241m=\u001b[39m force_text(stdout, defenc)\n\u001b[0;32m    117\u001b[0m stderr \u001b[38;5;241m=\u001b[39m force_text(stderr, defenc)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HookExecutionError(hp, process\u001b[38;5;241m.\u001b[39mreturncode, stderr, stdout)\n",
      "\u001b[1;31mHookExecutionError\u001b[0m: Hook('c:\\Users\\maria\\Desktop\\dsl_ft_33\\00_Projets_certif\\bloc4\\03_Jedha_aia_bloc_4_Final_project\\wakee_lead\\src\\WAKEE_reloaded_API\\.git\\hooks\\post-commit') failed due to: exit code(2)\n  cmdline: c:\\Users\\maria\\Desktop\\dsl_ft_33\\00_Projets_certif\\bloc4\\03_Jedha_aia_bloc_4_Final_project\\wakee_lead\\src\\WAKEE_reloaded_API\\.git\\hooks\\post-commit\n  stderr: '\nThis repository is configured for Git LFS but 'git-lfs' was not found on your path. If you no longer wish to use Git LFS, remove this hook by deleting the 'post-commit' file in the hooks directory (set by 'core.hookspath'; usually '.git/hooks').\n\n'"
     ]
    }
   ],
   "source": [
    "repo.index.commit(\"API model update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98a3256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = repo.index.diff(repo.head.commit)\n",
    "for d in diffs:\n",
    "    print(d.a_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f7d0d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Git\\cmd\\git.EXE\n",
      "C:\\Users\\maria\\.conda\\envs\\wakee_rldd\\Library\\bin\\git-lfs.EXE\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "print(shutil.which(\"git\"))\n",
    "print(shutil.which(\"git-lfs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97253ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Git\\cmd\\git.exe\n",
      "C:\\Program Files\\Git\\mingw64\\bin\\git.exe\n",
      "git version 2.53.0.windows.1\n",
      "C:\\Program Files\\Git\\cmd\\git-lfs.exe\n",
      "C:\\Program Files\\Git\\mingw64\\bin\\git-lfs.exe\n"
     ]
    }
   ],
   "source": [
    "import git\n",
    "print(git.Git().execute([\"where\", \"git\"]))\n",
    "print(git.Git().execute([\"git\", \"--version\"]))\n",
    "print(git.Git().execute([\"where\", \"git-lfs\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a1cf86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Git\\cmd\\git-lfs.exe\n",
      "C:\\Program Files\\Git\\mingw64\\bin\\git-lfs.exe\n"
     ]
    }
   ],
   "source": [
    "print(git.Git().execute([\"where\", \"git-lfs\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed11aa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\.conda\\envs\\wakee_rldd;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\java8path;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files (x86)\\VMware\\VMware Workstation\\bin\\;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\NVIDIA App\\NvDLISR;C:\\ProgramData\\chocolatey\\bin;C:\\Program Files\\dotnet\\;C:\\Program Files\\Docker\\Docker\\resources\\bin;C:\\Program Files\\Git LFS;C:\\Program Files\\Git\\cmd;C:\\Program Files\\Git\\mingw64\\bin;C:\\Program Files\\Git\\usr\\bin;C:\\Users\\maria\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\maria\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Program Files\\Graphviz\\bin;C:\\Users\\maria\\AppData\\Local\\Coursier\\data\\bin;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\java8path;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files (x86)\\VMware\\VMware Workstation\\bin\\;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\NVIDIA App\\NvDLISR;C:\\ProgramData\\chocolatey\\bin;C:\\Program Files\\dotnet\\;C:\\Program Files\\Docker\\Docker\\resources\\bin;C:\\Program Files\\Git LFS;C:\\Program Files\\Git\\cmd;C:\\Program Files\\Git\\mingw64\\bin;C:\\Program Files\\Git\\usr\\bin;C:\\Users\\maria\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\maria\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Program Files\\Graphviz\\bin;C:\\Users\\maria\\AppData\\Local\\Coursier\\data\\bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b8b8dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Git\\cmd\\git.exe\n",
      "C:\\Program Files\\Git\\mingw64\\bin\\git.exe\n",
      "git version 2.53.0.windows.1\n"
     ]
    }
   ],
   "source": [
    "import git\n",
    "print(git.Git().execute([\"where\", \"git\"]))\n",
    "print(git.Git().execute([\"git\", \"--version\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d59e570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cmd/git-lfs\n"
     ]
    }
   ],
   "source": [
    "repo = git.Repo(\"WAKEE_reloaded_API\")\n",
    "print(repo.git.execute([\"which\", \"git-lfs\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69deb8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GIT_PYTHON_GIT_EXECUTABLE\"] = r\"C:\\Program Files\\Git\\cmd\\git.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93388be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "repo = Repo(\"WAKEE_reloaded_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39276b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.git.add([\"model/daisee_model.onnx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8314dc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.git.add([\".github/workflows/deploy-api.yml\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb6e755a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[main 0922a6e] workflow update\\n 1 file changed, 2 insertions(+)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.git.commit(\"-m\", \"workflow update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd246628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.git.push(\"origin\", \"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "###BACKUP\n",
    "\n",
    "- name: üöÄ Deploy to HuggingFace Space\n",
    "        env:\n",
    "          HF_TOKEN: ${{ secrets.HF_TOKEN }}\n",
    "          SPACE_NAME: Mevelios/WAKEE.reloaded_API\n",
    "        run: |\n",
    "          # install git LFS because .onnx tracking\n",
    "          git lfs install\n",
    "\n",
    "          # Configuration Git\n",
    "          git config --global user.name \"github-actions[bot]\"\n",
    "          git config --global user.email \"github-actions[bot]@users.noreply.github.com\"\n",
    "          \n",
    "          # Clone avec authentification\n",
    "          git clone https://Mevelios:$HF_TOKEN@huggingface.co/spaces/$SPACE_NAME space_repo\n",
    "\n",
    "          # pull LFS file (model.onnx)\n",
    "          cd space_repo\n",
    "          git lfs pull\n",
    "          cd ..\n",
    "          \n",
    "          # Cr√©er structure de dossiers\n",
    "          echo \"üìÅ Cr√©ation des dossiers...\"\n",
    "          mkdir -p space_repo/model\n",
    "          mkdir -p space_repo/static\n",
    "          mkdir -p space_repo/templates\n",
    "\n",
    "          # V√©rifier que les fichiers sources existent\n",
    "          echo \"üîç V√©rification des fichiers sources...\"\n",
    "          ls -lh app.py cnn.py llm.py model/daisee_model.onnx\n",
    "\n",
    "          # Copie des fichiers et sous dossier\n",
    "          echo \"üìã Copie des fichiers...\"\n",
    "          cp app.py space_repo/\n",
    "          cp cnn.py space_repo/\n",
    "          cp llm.py space_repo/\n",
    "          cp requirements.txt space_repo/\n",
    "          cp Dockerfile space_repo/\n",
    "\n",
    "          echo \"üìã Copie des sous-dossiers...\"\n",
    "          cp model/daisee_model.onnx space_repo/model/daisee_model.onnx\n",
    "          cp static/style.css space_repo/static/style.css\n",
    "          cp templates/index.html space_repo/templates/index.html\n",
    "\n",
    "          [ -f README.md ] && cp README.md space_repo/\n",
    "          \n",
    "          # V√©rifier ce qui a √©t√© copi√©\n",
    "          echo \"üìÇ Contenu de space_repo :\"\n",
    "          ls -lhR space_repo/\n",
    "\n",
    "          # Commit et push\n",
    "          cd space_repo\n",
    "          git add .\n",
    "          git commit -m \"üöÄ Deploy from GitHub Actions - $(date '+%Y-%m-%d %H:%M:%S')\"\n",
    "          git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f51d1c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "To use CloudWorkspace you must provide a token through argument or env variable EVIDENTLY_API_KEY",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mevidently\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mui\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkspace\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CloudWorkspace\n\u001b[1;32m----> 3\u001b[0m ws \u001b[38;5;241m=\u001b[39m \u001b[43mCloudWorkspace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEVIDENTLY_AI_TOKEN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://app.evidently.cloud\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m ws\u001b[38;5;241m.\u001b[39mlist_projects()\n",
      "File \u001b[1;32mc:\\Users\\maria\\.conda\\envs\\wakee_rldd\\lib\\site-packages\\evidently\\ui\\workspace.py:1346\u001b[0m, in \u001b[0;36mCloudWorkspace.__init__\u001b[1;34m(self, token, url)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     token \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEVIDENTLY_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1346\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use CloudWorkspace you must provide a token through argument or env variable EVIDENTLY_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1348\u001b[0m     )\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken \u001b[38;5;241m=\u001b[39m token\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_cookie_name \u001b[38;5;241m=\u001b[39m ACCESS_TOKEN_COOKIE\u001b[38;5;241m.\u001b[39mkey\n",
      "\u001b[1;31mValueError\u001b[0m: To use CloudWorkspace you must provide a token through argument or env variable EVIDENTLY_API_KEY"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from evidently.ui.workspace import CloudWorkspace\n",
    "ws = CloudWorkspace(\n",
    "        token=os.getenv(\"EVIDENTLY_AI_TOKEN\"),\n",
    "        url=\"https://app.evidently.cloud\"\n",
    "    )\n",
    "ws.list_projects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b716b546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Project ID: 019c6b19-9521-7aa0-9d93-496daf0869ea\n",
       " Project Name: WAKEE.reloaded\n",
       " Project Description: AIA certification\n",
       "         ,\n",
       " Project ID: 0196263b-b086-7f35-827b-bfef55a33ecc\n",
       " Project Name: Health assistant demo\n",
       " Project Description: This project was automatically generated by evidently\n",
       "         ]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from evidently.ui.workspace import CloudWorkspace\n",
    "ws = CloudWorkspace(\n",
    "        token=os.getenv(\"EVIDENTLY_API_KEY\"),\n",
    "        url=\"https://app.evidently.cloud\"\n",
    "    )\n",
    "ws.list_projects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd4afcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.7.20'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evidently\n",
    "evidently.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
